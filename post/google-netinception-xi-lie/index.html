<html>
  <head>
    <meta charset="utf-8" />
<meta name="description" content="" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>GoogLe Net（Inception 系列） | Yoxode</title>
<link rel="shortcut icon" href="https://Yoxode.github.io/favicon.ico">
<link rel="stylesheet" href="https://Yoxode.github.io/styles/main.css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.bootcss.com/moment.js/2.23.0/moment.min.js"></script>


  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://Yoxode.github.io">
  <img class="avatar" src="https://Yoxode.github.io/images/avatar.png" alt="" width="80px" height="80px">
  </a>
  <h1 class="site-title">
    Yoxode
  </h1>
  <p class="site-description">
    Program myself.
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
</div>

      
        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              GoogLe Net（Inception 系列）
            </h2>
            <div class="post-info">
              <time class="post-time">
                · 2019-03-04 ·
              </time>
              
            </div>
            <div class="post-content">
              <p>Inception V1、V2、V3、V4</p>
<!-- more -->
<h1 id="google net简介">GoogLe Net简介</h1><p><strong>2014</strong>年，GoogLeNet和VGG是当年ImageNet挑战赛(ILSVRC14)的双雄，GoogLeNet获得了<strong>第一名</strong>、VGG获得了第二名，这两类模型结构的共同特点是<strong>层次更深</strong>了。VGG继承了LeNet以及AlexNet的一些框架结构（详见  大话CNN经典模型：VGGNet），而GoogLeNet则做了更加大胆的网络结构尝试，虽然<strong>深度只有22层</strong>，但大小却比AlexNet和VGG小很多，GoogleNet<strong>参数为500万</strong>个，AlexNet参数个数是GoogleNet的12倍，VGGNet参数又是AlexNet的3倍，因此在内存或计算资源有限时，GoogleNet是比较好的选择；从模型结果来看，GoogLeNet的<strong>性能却更加优越</strong>。</p>
<h1 id="inception">Inception</h1><p>一般来说，提升网络性能最直接的办法就是<strong>增加网络深度和宽度</strong>，深度指<strong>网络层次数量</strong>、宽度指<strong>神经元数量</strong>。但这种方式存在以下问题：</p>
<ol>
<li>参数太多，如果训练数据集有限，很容易产生<strong>过拟合</strong></li>
<li>网络越大、参数越多，<strong>计算复杂度越大</strong>，难以应用</li>
<li>网络越深，容易出现<strong>梯度弥散</strong>问题（梯度越往后穿越容易消失），难以优化模型</li>
</ol>
<p>解决这些问题的方法当然就是在增加网络深度和宽度的同时减少参数，为了减少参数，自然就想到将全连接变成<strong>稀疏连接</strong>。但是在实现上，全连接变成稀疏连接后实际计算量并不会有质的提升，因为大部分硬件是针对<strong>密集矩阵计算优化</strong>的，稀疏矩阵虽然数据量少，但是计算所消耗的时间却很难减少。</p>
<p>大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，就如人类的大脑是可以看做是神经元的重复堆积，因此，<strong>GoogLeNet团队</strong>提出了<strong>Inception</strong>网络结构，就是构造一种“基础神经元”结构，来搭建一个稀疏性、高计算性能的网络结构。</p>
<h1 id="inception v1">Inception V1</h1><ol>
<li>简介<br>Inception V1有 <strong>9 个线性堆叠的 Inception 模块</strong>，总共有<strong>22层</strong>（包括池化层的话是27层，最后一个 inception 模块处使用<strong>全局平均池化</strong>），而AlexNet和VGGNet分别为8层和19层，但它的参数量只有<strong>500万</strong>个，而AlexNet却有6000万个，仅为1/12，但是准确率远高于AlexNet。</li>
<li>背景<br>虽然增加神经网络的规模可以提高性能，但有两个缺点：<ul>
<li>参数过多更容易导致过拟合，并且高质量的训练集需要更高的成本。</li>
<li>增加里计算机资源的使用，网络太大，计算复杂程度大，模型训练也困难。</li>
</ul>
</li>
<li>Inception模块<br><img src="https://Yoxode.github.io/post-images/1551821658754.png" alt=""><br><strong>图a</strong>是论文中提出的最原始的版本，所有的卷积核都在上一层的所有输出上来做，那5×5的卷积核所需的计算量就太大了，造成了特征图厚度很大。为了避免这一现象提出的inception具有如下结构，在3x3前，5x5前，max pooling后分别加上了1x1的卷积核起到了降低特征图厚度的作用，也就是<strong>图b</strong>中Inception v1的网络结构。<ul>
<li>a. 不同的尺寸的卷积核代表着不同的感受野，卷积核大小采用1×1、3×3、5×5，主要是为了<strong>方便对齐</strong>。设定卷积步长stride=1之后，分别设定pad=0、1、2，卷积之后便可以得到<strong>相同维度</strong>的特征，然后将特征通过<strong>Filter concatenation</strong>直接<strong>拼接</strong>在一起。（打个比方3个10x10x3的图按照深度连接起来就会变成一个10x10x9的图，所以Filter Concatenation就这么简单，把几个图连成一个而已）</li>
<li>b. 第一个分支对输入进行了1×1卷积，第二个分支先1×1卷积后3×3卷积，第三个先1×1卷积后5×5卷积，第四个先3×3最大池化后1×1卷积，可以发现一个共性，<strong>都进行了1×1的卷积</strong>，这是因为<strong>1×1卷积可以用很小的计算量添加一层特征变换和非线性化，并且采用1×1卷积来进行将维</strong>，例如：上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，大约减少了4倍。所以<strong>用1×1卷积核降维大大减少了参数量，有效减小了计算的复杂程度</strong>。</li>
</ul>
</li>
<li>结构图<br><img src="https://Yoxode.github.io/post-images/1551821437191.png" alt=""></li>
<li>参数表<br><img src="https://Yoxode.github.io/post-images/1551821474935.png" alt=""></li>
<li>结构说明<ul>
<li>Global Average Pooling（全局平均池化）<br>最终的卷积层之后采用Global Average Pooling层，而不是全连接层，这有助于<strong>减少参数量</strong><br><img src="https://Yoxode.github.io/post-images/1551824807166.png" alt=""></li>
<li>辅助损失<br>除了上述所说的，为了阻止该网络中间部分梯度消失过程，作者引入了两个辅助分类器。它们对其中两个 Inception 模块的输出执行 softmax 操作，然后在同样的标签上计算<strong>辅助损失</strong>。总损失即辅助损失和真实损失的加权和。该论文中对每个辅助损失使用的权重值是<strong>0.3</strong>。<br>（文中说是为了避免梯度消失问题，也是一种正则化手段。）<blockquote>
<p># The total loss used by the inception net during training.<br>total_loss = real_loss + 0.3 * aux_loss_1 + 0.3 * aux_loss_2</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<h1 id="inception v2">Inception V2</h1><ol>
<li>简介<br><strong>Inception v2</strong> 和 <strong>Inception v3</strong> 来自同一篇论文《<em>Rethinking the Inception Architecture for Computer Vision</em>》，作者提出了一系列能<strong>增加准确度</strong>和<strong>减少计算复杂度</strong>的修正方法。</li>
<li>改进<ul>
<li>加入了<strong>BN</strong>（Batch Normalization）层，减少了InternalCovariate Shift（内部neuron的数据分布发生变化），使每一层的输出都规范化到一个N(0, 1)的高斯分布，从而增加了模型的鲁棒性，可以以更大的学习速率训练，收敛更快，初始化操作更加随意，同时作为一种正则化技术，可以减少dropout层的使用。</li>
<li>用2个连续的3×3 conv替代inception模块中的5×5，从而实现网络深度的增加，网络整体深度增加了9层。<br><img src="https://Yoxode.github.io/post-images/1551825909233.jpg" alt=""></li>
</ul>
</li>
</ol>
<h1 id="inception v3">Inception V3</h1><ol>
<li>简介<br>Inception v3网络，主要在v2的基础上，提出了<strong>卷积分解（Factorization）</strong>，代表作是Inceptionv3版本的GoogleNet。</li>
<li>改进<ul>
<li>将7×7分解成<strong>两个一维的卷积</strong>（1×7,7×1），3×3也是一样（1×3,3×1），这样的好处，既可以<strong>加速计算</strong>（多余的计算能力可以用来加深网络），又可以将1个conv拆成2个conv，使得<strong>网络深度进一步增加</strong>，增加了网络的非线性，更加精细设计了35×35、17×17、8×8的模块。<br><img src="https://Yoxode.github.io/post-images/1551826376435.jpg" alt=""></li>
<li>增加网络宽度，网络输入从224×224变为了299×299。</li>
</ul>
</li>
</ol>
<h1 id="inception v4, inception-resnet">Inception V4, Inception-ResNet</h1><ol>
<li>简介<br>Inception v4主要利用<strong>残差连接</strong>（<strong>Residual Connection</strong>）来改进v3结构，代表作为，Inception-ResNet-v1，Inception-ResNet-v2，Inception-v4。</li>
<li>残差结构<br>resnet中的残差结构如下，这个结构设计的就很巧妙，简直神来之笔，使用原始层和经过2个卷基层或者3个卷积层的feature map做Eltwise。<br>首先介绍几个概念，左边的3×3+3×3(ResNet18，ResNet34)和1×1+3×3+1×1（ResNet50，ResNet101，ResNet152）称为<strong>瓶颈单元</strong>（<strong>bootlenect</strong>，因为输入为256，中间为64，输出为256，宽窄宽的结构，像瓶子的颈部）。右面的直线，有的实现是直线中有1×1卷积，称为<strong>shortcut</strong>。整个bootlenect+shortcut称为<strong>Residual uint</strong>。几个Residual uint的叠加称为<strong>Residual block</strong>。Resnet结构都是由<strong>4个Residual block</strong>组成的。<br>Inception-ResNet的改进就是使用上文的Inception module来替换resnet shortcut中的bootlenect。<br><img src="https://Yoxode.github.io/post-images/1551828058494.png" alt=""></li>
</ol>
<p>参考：<br><a href="https://zhuanlan.zhihu.com/p/37505777">从Inception v1到Inception-ResNet，一文概览Inception家族的「奋斗史」</a><br><a href="https://blog.csdn.net/qq_14845119/article/details/73648100">从Inception v1,v2,v3,v4,RexNeXt到Xception再到MobileNets,ShuffleNet,MobileNetV2,ShuffleNetV2</a><br><a href="https://blog.csdn.net/qq_28132591/article/details/64124491">Filter Concatenation的理解</a><br><a href="https://my.oschina.net/u/876354/blog/1637819">大话CNN经典模型：GoogLeNet（从Inception v1到v4的演进）</a></p>

            </div>
          </article>
        </div>
    
        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://Yoxode.github.io/post/ji-huo-han-shu">
              <h3 class="post-title">
                激活函数
              </h3>
            </a>
          </div>  
        

        
    
        <div class="site-footer">
  Powered by yoxode.
</div>

<script>
  hljs.initHighlightingOnLoad()
</script>

      </div>
    </div>
  </body>
</html>
